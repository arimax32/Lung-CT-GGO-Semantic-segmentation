{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO6JxBaYcLgH7aSeZCgMjUq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arimax32/Lung-CT-GGO-Semantic-segmentation/blob/main/Segment_GGO_Patches.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kf3Y4HBMExGk"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = '/content'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod 600 /content/kaggle.json"
      ],
      "metadata": {
        "id": "mF1hePmoE_hk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle kernels output aritra20datta/patch-ggo -p /content"
      ],
      "metadata": {
        "id": "kGcHPXROFBul",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf491892-1813-4949-e503-c1469bc38b60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output file downloaded to /content/_output_.zip\n",
            "Kernel log downloaded to /content/patch-ggo.log \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \\*.zip && rm *.zip"
      ],
      "metadata": {
        "id": "TNGi_KA7hAAP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open('ggo_mask.pkl', 'rb') as fp:\n",
        "    img_mask = pickle.load(fp)\n",
        "    print(img_mask)"
      ],
      "metadata": {
        "id": "uS2EIGqB0I2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics"
      ],
      "metadata": {
        "id": "hSl0SZXsTf3A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install segmentation_models_pytorch"
      ],
      "metadata": {
        "id": "Tz6p3b56TjIr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torchvision import transforms\n",
        "import torchvision.transforms.functional as TF\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from torchmetrics.classification import Dice, BinaryJaccardIndex, BinaryAccuracy, BinaryF1Score, BinaryPrecision, BinaryRecall\n",
        "from google.colab.patches import cv2_imshow\n",
        "from tqdm import tqdm\n",
        "import segmentation_models_pytorch as smp\n",
        "import re\n",
        "import time"
      ],
      "metadata": {
        "id": "vK9HpWEgTk1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SegmentationDataset(Dataset):\n",
        "\n",
        "    def __init__(self, mask_paths, img_mask_map, transform=None) -> None:\n",
        "        super().__init__()\n",
        "        self.transform = transform\n",
        "        self.img_mask_map = img_mask_map\n",
        "        self.masks = []\n",
        "\n",
        "        for path in mask_paths:\n",
        "            img_list = os.listdir(path)\n",
        "            imgs = [(p,path) for p in img_list]\n",
        "            self.masks.extend(imgs)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.masks)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        mask_name = self.masks[index][0]\n",
        "        mask_path = self.masks[index][1]\n",
        "\n",
        "        base_img, patch = self.extract_base_filename(mask_name)\n",
        "        ggo_name = f\"{self.img_mask_map[base_img]}{patch}.jpg\"\n",
        "        ggo_path = self.extract_base_path(mask_path)\n",
        "\n",
        "        image = cv2.imread( os.path.join(ggo_path,ggo_name),0).astype(np.float32)\n",
        "        mask =  cv2.imread(os.path.join(mask_path,mask_name), 0).astype(np.float32)\n",
        "        image = image/255.0\n",
        "        mask[mask == 255] = 1.0\n",
        "\n",
        "        if self.transform:\n",
        "          augmentations = self.transform(image=image,mask=mask)\n",
        "          image = augmentations[\"image\"]\n",
        "          mask = augmentations[\"mask\"]\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "    def extract_base_filename(self, full_filename):\n",
        "      # Define the pattern to match filenames like 'LIDC-IDRI-0001_86_mask_patch_i_j.png'\n",
        "      pattern = re.compile(r'^(.+)_((?:mask|img)_patch_\\d+_\\d+)\\.(.+)$')\n",
        "\n",
        "      # Use the pattern to extract the base filename and _patch_i_j\n",
        "      match = pattern.match(full_filename)\n",
        "      if match:\n",
        "          base_filename = f\"{match.group(1)}_img.{match.group(3)}\"\n",
        "          patch_info = match.group(2).replace('_img', '').replace('mask', '')\n",
        "          return base_filename, patch_info\n",
        "      else:\n",
        "          return None, None  # No match\n",
        "\n",
        "    def extract_base_path(self, path):\n",
        "      directory, filename = os.path.split(path)\n",
        "      new_filename = filename.replace('mask', 'ggo')\n",
        "      new_path = os.path.join(directory, new_filename)\n",
        "      return new_path\n"
      ],
      "metadata": {
        "id": "12w16bteTnpN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_transform = A.Compose([\n",
        "    A.Rotate(limit=50,p=0.5,border_mode=cv2.BORDER_CONSTANT),\n",
        "    A.VerticalFlip(p=0.10),\n",
        "    ToTensorV2(),\n",
        "])\n",
        "\n",
        "test_transform = A.Compose([\n",
        "    ToTensorV2(),\n",
        "])"
      ],
      "metadata": {
        "id": "AmCtTYftid26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "LR = 0.001\n",
        "EPOCHS = 20\n",
        "BATCH_SIZE = 16\n",
        "PIN_MEMORY = True\n",
        "NUM_WORKERS = 2"
      ],
      "metadata": {
        "id": "En3jrSHSi_gx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MixedBCELoss(nn.Module):\n",
        "    def __init__(self, weight=None,size_average=True):\n",
        "        super(MixedBCELoss, self).__init__()\n",
        "\n",
        "    def forward(self, inputs, targets, smooth=1):\n",
        "\n",
        "        #flatten label and prediction tensors\n",
        "        inputs = inputs.view(-1)\n",
        "        targets = targets.view(-1)\n",
        "        loss = nn.BCEWithLogitsLoss()\n",
        "        BCE = loss(inputs, targets)\n",
        "\n",
        "        inputs = torch.sigmoid(inputs)\n",
        "        intersection = (inputs * targets).sum()\n",
        "        union = inputs.sum() + targets.sum()\n",
        "        dice_loss = 1 - (2.*intersection + smooth)/(union + smooth)\n",
        "        jaccard_loss = 1 - ((intersection + smooth)/(union - intersection + smooth))\n",
        "\n",
        "        Mixed_BCE = BCE + jaccard_loss\n",
        "        return Mixed_BCE"
      ],
      "metadata": {
        "id": "60v-pMK1jC4E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_paths = ['/content/mask-patches-7','/content/mask-patches-6']\n",
        "test_paths = ['/content/mask-patches-5','/content/mask-patches-4']"
      ],
      "metadata": {
        "id": "CDius8pWj4vV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train and test datasets\n",
        "train_dataset = SegmentationDataset(mask_paths = train_paths,\n",
        "                                    img_mask_map = img_mask, transform = train_transform)\n",
        "test_dataset = SegmentationDataset(mask_paths = test_paths,\n",
        "                                    img_mask_map = img_mask, transform = test_transform)\n",
        "\n",
        "# training and test data loaders\n",
        "trainLoader = DataLoader(train_dataset, shuffle=False, batch_size=BATCH_SIZE,\n",
        "                         pin_memory=PIN_MEMORY, num_workers=NUM_WORKERS)\n",
        "testLoader = DataLoader(test_dataset, shuffle=False, batch_size=BATCH_SIZE,\n",
        "                        pin_memory=PIN_MEMORY, num_workers=NUM_WORKERS)"
      ],
      "metadata": {
        "id": "_OR7CPFxjhyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = smp.DeepLabV3('resnet101', encoder_weights='imagenet',in_channels=1, classes=1).to(DEVICE)"
      ],
      "metadata": {
        "id": "8G1mL3rTj-AV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d0e93a8-de17-4301-c3b7-a55d65e00a97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet101-5d3b4d8f.pth\" to /root/.cache/torch/hub/checkpoints/resnet101-5d3b4d8f.pth\n",
            "100%|██████████| 170M/170M [00:01<00:00, 147MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = MixedBCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "scaler = torch.cuda.amp.GradScaler()"
      ],
      "metadata": {
        "id": "NWw8m_nKkAd-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model():\n",
        "  running_train_loss = 0\n",
        "  for (images, masks) in trainLoader:\n",
        "\n",
        "      images = images.to(DEVICE)\n",
        "      masks = masks.to(DEVICE).unsqueeze(1)\n",
        "      masks = (masks > 0.5).type('torch.ByteTensor').to(DEVICE)\n",
        "\n",
        "      with torch.cuda.amp.autocast():\n",
        "        preds = model(images)\n",
        "        train_loss = loss(preds, masks.float())\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      scaler.scale(train_loss).backward()\n",
        "      scaler.step(optimizer)\n",
        "      scaler.update()\n",
        "\n",
        "      running_train_loss += train_loss.item()\n",
        "\n",
        "\n",
        "  return running_train_loss / len(trainLoader)\n",
        "\n",
        "def eval_model():\n",
        "  running_test_loss = 0\n",
        "  intersection_over_unions, dice_scores, accuracy, f1_Score, precision, recall = [], [], [], [], [], []\n",
        "  iou = BinaryJaccardIndex().to(DEVICE)\n",
        "  dice = Dice().to(DEVICE)\n",
        "  for (images, masks) in testLoader:\n",
        "\n",
        "    images = images.to(DEVICE)\n",
        "    masks = masks.to(DEVICE).unsqueeze(1)\n",
        "    masks = (masks > 0.5).type('torch.ByteTensor').to(DEVICE)\n",
        "\n",
        "    preds = model(images)\n",
        "    if preds.isnan().any():\n",
        "      print(f\"Nan Batch\")\n",
        "      continue\n",
        "\n",
        "    test_loss = loss(preds, masks.float())\n",
        "\n",
        "    preds = torch.sigmoid(preds)\n",
        "    preds = (preds > 0.5).type('torch.ByteTensor').to(DEVICE)\n",
        "\n",
        "    dice_scores.append(dice(preds,masks).item())\n",
        "    if not torch.any(preds) and not torch.any(masks):\n",
        "      intersection_over_unions.append(1.0)\n",
        "    else:\n",
        "      intersection_over_unions.append(iou(preds,masks).item())\n",
        "\n",
        "    running_test_loss += test_loss.item()\n",
        "\n",
        "  return running_test_loss / len(testLoader), intersection_over_unions, dice_scores\n",
        "\n",
        "def run_model():\n",
        "  train_losses, test_losses = [], []\n",
        "  for e in tqdm(range(EPOCHS)):\n",
        "    model.train()\n",
        "    start_time = time.time()\n",
        "    training_loss = train_model()\n",
        "    test_loss = 0\n",
        "    train_losses.append(training_loss)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      model.eval()\n",
        "      test_loss, iou, dice = eval_model()\n",
        "      test_losses.append(test_loss)\n",
        "\n",
        "    end_time = time.time()\n",
        "    epoch_time = end_time - start_time\n",
        "\n",
        "    print(f\"\\nEpoch : [{e}] | Train Loss: {training_loss} | Test Loss: {test_loss}\")\n",
        "    print(f\"Mean Dice: {np.mean(dice)} | Mean Iou: {np.mean(iou)}\")\n",
        "    print(f\"Epoch finished in {epoch_time:.2f} seconds\")"
      ],
      "metadata": {
        "id": "dACczfnJkCvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "89121POmkF1d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_model()"
      ],
      "metadata": {
        "id": "Zu4YpwchkGa9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fff85c60-36c6-4ece-a664-ad2d0d5e2142"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 1/20 [07:43<2:26:49, 463.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch : [0] | Train Loss: 0.682338795549571 | Test Loss: 0.6618081510749879\n",
            "Mean Dice: 0.9995633465856457 | Mean Iou: 0.30808773132282385\n",
            "Epoch finished in 463.67 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 2/20 [14:58<2:14:04, 446.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch : [1] | Train Loss: 0.6338176253258825 | Test Loss: 0.6616888050197755\n",
            "Mean Dice: 0.9995633465856457 | Mean Iou: 0.30808773132282385\n",
            "Epoch finished in 435.20 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▌        | 3/20 [22:15<2:05:20, 442.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch : [2] | Train Loss: 0.6313850963726773 | Test Loss: 0.661690427932165\n",
            "Mean Dice: 0.9995633465856457 | Mean Iou: 0.30808773132282385\n",
            "Epoch finished in 436.97 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 4/20 [29:47<1:58:53, 445.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch : [3] | Train Loss: 0.632326867267834 | Test Loss: 0.661725770640645\n",
            "Mean Dice: 0.9995633465856457 | Mean Iou: 0.30808773132282385\n",
            "Epoch finished in 451.18 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 5/20 [37:06<1:50:54, 443.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch : [4] | Train Loss: 0.6301262211336947 | Test Loss: 0.661681103542796\n",
            "Mean Dice: 0.9995633465856457 | Mean Iou: 0.30808773132282385\n",
            "Epoch finished in 439.63 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 6/20 [44:27<1:43:16, 442.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch : [5] | Train Loss: 0.6325392208879673 | Test Loss: 0.6616713943883408\n",
            "Mean Dice: 0.9995633465856457 | Mean Iou: 0.30808773132282385\n",
            "Epoch finished in 440.66 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▌      | 7/20 [51:57<1:36:25, 445.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch : [6] | Train Loss: 0.6318374290468316 | Test Loss: 0.6616054849342553\n",
            "Mean Dice: 0.9995633465856457 | Mean Iou: 0.30808773132282385\n",
            "Epoch finished in 450.07 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 8/20 [59:16<1:28:38, 443.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch : [7] | Train Loss: 0.63526669047669 | Test Loss: 0.6617007396862372\n",
            "Mean Dice: 0.9995633465856457 | Mean Iou: 0.30808773132282385\n",
            "Epoch finished in 439.34 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|████▌     | 9/20 [1:06:37<1:21:06, 442.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch : [8] | Train Loss: 0.6314339806171058 | Test Loss: 0.6616142120633135\n",
            "Mean Dice: 0.9995633465856457 | Mean Iou: 0.30808773132282385\n",
            "Epoch finished in 440.69 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 10/20 [1:14:08<1:14:12, 445.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch : [9] | Train Loss: 0.6302730545322086 | Test Loss: 0.6615946936787577\n",
            "Mean Dice: 0.9995633465856457 | Mean Iou: 0.30808773132282385\n",
            "Epoch finished in 451.39 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), f'MODEL_epochs_{EPOCHS}__state_dict.pth')"
      ],
      "metadata": {
        "id": "Fb_FqoARkLcg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}